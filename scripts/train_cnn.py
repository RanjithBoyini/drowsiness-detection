import os
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ‚úÖ Automatically get the dataset folder path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # Gets the 'scripts' folder path
PROJECT_DIR = os.path.dirname(BASE_DIR)  # Moves one level up to the main project folder

TRAIN_DIR = os.path.join(PROJECT_DIR, "dataset/train")
VAL_DIR = os.path.join(PROJECT_DIR, "dataset/val")

# ‚úÖ Step 1: Check if dataset folders exist
print(f"üîç Checking dataset paths...")
print(f"TRAIN_DIR: {TRAIN_DIR}")
print(f"VAL_DIR: {VAL_DIR}")

if not os.path.exists(TRAIN_DIR):
    raise FileNotFoundError(f"‚ùå Train directory not found: {TRAIN_DIR}")
if not os.path.exists(VAL_DIR):
    raise FileNotFoundError(f"‚ùå Validation directory not found: {VAL_DIR}")

# ‚úÖ Step 2: Check if dataset contains images
def count_images(folder):
    return sum([len(files) for _, _, files in os.walk(folder)])

num_train_images = count_images(TRAIN_DIR)
num_val_images = count_images(VAL_DIR)

print(f"üì∏ Training images: {num_train_images}")
print(f"üì∏ Validation images: {num_val_images}")

if num_train_images == 0 or num_val_images == 0:
    raise ValueError("üö® Error: No images found in dataset! Add images to 'train/' and 'val/' folders.")

# ‚úÖ Step 3: Define image size and batch size
IMG_SIZE = (224, 224)
BATCH_SIZE = 32

# ‚úÖ Step 4: Data augmentation & preprocessing
datagen = ImageDataGenerator(rescale=1./255)

train_generator = datagen.flow_from_directory(
    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')

val_generator = datagen.flow_from_directory(
    VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')

# ‚úÖ Step 5: Define CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Binary classification (alert vs. drowsy)
])

# ‚úÖ Step 6: Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ‚úÖ Step 7: Train the model
print("\nüöÄ Training CNN Model...\n")
model.fit(train_generator, validation_data=val_generator, epochs=10)

# ‚úÖ Step 8: Save the trained model dynamically
MODEL_DIR = os.path.join(PROJECT_DIR, "models")
os.makedirs(MODEL_DIR, exist_ok=True)  # Create 'models' folder if it doesn't exist

MODEL_PATH = os.path.join(MODEL_DIR, "cnn_drowsiness.h5")
model.save(MODEL_PATH)

print(f"\n‚úÖ CNN Model Trained and Saved at: {MODEL_PATH}")
